"""
Streamlit Page: Live Congestion Prediction Demo
Interactive demo showing how the model predicts future congestion.
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from pathlib import Path
import joblib
import json

# Page config
st.set_page_config(page_title="Live Predictions", page_icon="üîÆ", layout="wide")

# Title
st.title("üîÆ Live Congestion Prediction")
st.markdown("---")

st.info("""
**How it works:** The model analyzes traffic patterns in 50-slot windows and predicts if 
congestion will occur **50 slots ahead**. This early warning enables proactive network management.

**Note:** The model predicts the FUTURE state (50 slots ahead), not the current window state.
""")

# Load model and data
@st.cache_resource
def load_model_artifacts():
    """Load trained model, scaler, and feature names."""
    models_dir = Path("models")
    
    if not models_dir.exists():
        return None, None, None
    
    # Use refactored model (no data leakage)
    model_path = models_dir / "congestion_predictor.pkl"
    scaler_path = models_dir / "scaler.pkl"
    features_path = models_dir / "feature_names.json"
    
    if not all(p.exists() for p in [model_path, scaler_path, features_path]):
        return None, None, None
    
    model = joblib.load(model_path)
    scaler = joblib.load(scaler_path)
    
    with open(features_path, 'r') as f:
        feature_names = json.load(f)
    
    return model, scaler, feature_names

@st.cache_data
def load_sample_data():
    """Load feature data for demo."""
    features_file = Path("data/sliding_window_features.csv")
    if features_file.exists():
        df = pd.read_csv(features_file)
        
        # Create future congestion labels (same logic as training)
        df['future_congestion'] = 0
        
        for link in df['link_id'].unique():
            link_mask = df['link_id'] == link
            link_df = df[link_mask].sort_values('window_start_slot').copy()
            
            # Shift utilization and loss 50 slots forward
            future_util = link_df['avg_utilization'].shift(-50)
            future_loss = link_df['loss_rate'].shift(-50)
            
            # Label congestion if future util > 0.8 OR future loss > 0.1
            future_congestion = ((future_util > 0.8) | (future_loss > 0.1)).fillna(0).astype(int)
            
            df.loc[link_mask, 'future_congestion'] = future_congestion
        
        # Remove windows where we can't predict
        df = df[df['future_congestion'].notna()].copy()
        df['future_congestion'] = df['future_congestion'].astype(int)
        
        return df
    return None

model, scaler, feature_names = load_model_artifacts()
features_df = load_sample_data()

if model is None or features_df is None:
    st.error("‚ö†Ô∏è Model or data not found. Please train models first: `python src/train_realistic_model.py`")
    st.stop()

st.markdown("---")

# Calculate derived features if they don't exist
if 'throughput_acceleration' not in features_df.columns:
    # Sort by link and time
    features_df = features_df.sort_values(['link_id', 'window_start_slot'])
    
    # Calculate throughput_acceleration (rate of change of throughput_trend)
    features_df['throughput_acceleration'] = features_df.groupby('link_id')['throughput_trend'].diff().fillna(0)
    
    # Calculate burstiness (max_throughput / mean_throughput ratio)
    features_df['burstiness'] = features_df['max_throughput'] / (features_df['mean_throughput'] + 1e-6)
    features_df['burstiness'] = features_df['burstiness'].fillna(1.0)

# Interactive Selection
st.subheader("üéÆ Select a Window to Analyze")

col1, col2 = st.columns([2, 1])

with col1:
    link_options = features_df['link_id'].unique().tolist()
    selected_link = st.selectbox("üîó Select Link", link_options)

with col2:
    if st.button("üé≤ Get Random Window", type="primary"):
        st.rerun()

# Filter by link and get a truly random sample
link_data = features_df[features_df['link_id'] == selected_link]
sample = link_data.sample(1, random_state=np.random.randint(100000))

st.markdown("---")

# Display selected sample
if len(sample) > 0:
    row = sample.iloc[0]
    
    st.subheader("üìã Selected Window Details")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Link ID", row['link_id'])
        st.metric("Window Start", f"{int(row['window_start_slot'])}")
    
    with col2:
        st.metric("Mean Throughput", f"{row['mean_throughput']:.2f} Mbps")
        st.metric("Max Throughput", f"{row['max_throughput']:.2f} Mbps")
    
    with col3:
        st.metric("Std Throughput", f"{row['std_throughput']:.2f} Mbps")
        st.metric("Throughput Trend", f"{row['throughput_trend']:.4f}")
    
    with col4:
        st.metric("Loss Count", f"{int(row.get('loss_count', 0))}")
        loss_rate = row.get('loss_rate', 0.0) if 'loss_rate' in row else 0.0
        st.metric("Loss Rate", f"{loss_rate:.2%}")
    
    if int(row.get('loss_count', 0)) == 0:
        st.info("üí° **Note:** This window has loss_count=0 (no packet loss), but the model can still predict **future congestion** based on throughput patterns! The refactored model doesn't rely on packet loss - it triggers on max_throughput (84.88% importance).")
    
    st.markdown("---")
    
    # Make Prediction
    st.subheader("üîÆ Model Prediction (50 Slots Ahead)")
    
    target_slot = int(row['window_start_slot']) + 50
    st.info(f"üìä **Prediction Target:** Based on current window (slots {int(row['window_start_slot'])} to {int(row['window_end_slot'])}), what will the network state be at slot **{target_slot}**?")
    
    # Prepare features (SAFE FEATURES - NO LEAKAGE)
    # Must match EXACTLY the 12 features used in training:
    # ['mean_throughput', 'max_throughput', 'std_throughput', 'throughput_trend', 
    #  'throughput_acceleration', 'loss_count', 'time_since_last_loss', 'max_burst_length', 
    #  'burstiness', 'link_Link_1', 'link_Link_2', 'link_Link_3']
    
    feature_cols = [
        'mean_throughput', 'max_throughput', 'std_throughput', 
        'throughput_trend', 'throughput_acceleration', 'loss_count',
        'time_since_last_loss', 'max_burst_length', 'burstiness'
    ]
    
    # Extract feature values
    X = row[feature_cols].values.reshape(1, -1)
    
    # Add link encoding (one-hot for Link_1, Link_2, Link_3)
    link_features = []
    for link in ['Link_1', 'Link_2', 'Link_3']:
        link_features.append(1.0 if row['link_id'] == link else 0.0)
    
    X = np.hstack([X, np.array(link_features).reshape(1, -1)])
    
    # Scale and predict
    X_scaled = scaler.transform(X)
    prediction = model.predict(X_scaled)[0]
    prediction_proba = model.predict_proba(X_scaled)[0]
    
    confidence_normal = prediction_proba[0] * 100
    confidence_congested = prediction_proba[1] * 100
    
    # Display prediction
    col1, col2 = st.columns([1, 1])
    
    with col1:
        if prediction == 1:
            st.error("### üî¥ CONGESTION PREDICTED")
            st.metric("Confidence Level", f"{confidence_congested:.1f}%", delta=None)
            st.markdown("**‚ö†Ô∏è Predicted for 50 slots ahead:**")
            st.markdown(f"- High probability of congestion at slot **{target_slot}**")
            st.markdown("- Recommended action: Pre-emptive traffic shaping")
            st.markdown("- Alert operators for proactive intervention")
        else:
            st.success("### üü¢ NORMAL OPERATION")
            st.metric("Confidence Level", f"{confidence_normal:.1f}%", delta=None)
            st.markdown("**‚úÖ Predicted for 50 slots ahead:**")
            st.markdown("- Link expected to operate normally")
            st.markdown("- No intervention required")
            st.markdown("- Continue monitoring")
    
    with col2:
        # Probability distribution
        fig = go.Figure()
        
        fig.add_trace(go.Bar(
            x=['Normal', 'Congested'],
            y=[confidence_normal, confidence_congested],
            marker_color=['#10b981', '#ef4444'],
            text=[f'{confidence_normal:.1f}%', f'{confidence_congested:.1f}%'],
            textposition='outside'
        ))
        
        fig.update_layout(
            title="Prediction Probability Distribution",
            yaxis_title="Confidence (%)",
            yaxis_range=[0, 110],
            height=350
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Actual outcome
        actual = row['future_congestion']
        
        if actual == prediction:
            st.success(f"‚úÖ **Correct Prediction!** Model correctly predicted {'congestion' if actual == 1 else 'normal operation'}")
        else:
            st.warning(f"‚ö†Ô∏è **Prediction Mismatch:** Model predicted {'congestion' if prediction == 1 else 'normal'}, but actual was {'congestion' if actual == 1 else 'normal'}")
    
    st.markdown("---")
    
    # Feature Analysis
    st.subheader("üîç What Led to This Prediction?")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        feature_values = {
            'Mean Throughput': row['mean_throughput'],
            'Max Throughput': row['max_throughput'],
            'Std Throughput': row['std_throughput'],
            'Throughput Trend': row['throughput_trend'],
            'Time Since Last Loss': row['time_since_last_loss'],
            'Max Burst Length': row['max_burst_length']
        }
        
        fig = go.Figure()
        
        features = list(feature_values.keys())
        values = list(feature_values.values())
        
        fig.add_trace(go.Bar(
            y=features,
            x=values,
            orientation='h',
            marker_color=['#3b82f6' if v > 0 else '#ef4444' for v in values]
        ))
        
        fig.update_layout(
            title="Feature Values for This Window",
            xaxis_title="Value",
            height=400
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.markdown("**üí° Key Factors**")
        st.markdown("**Most Important Features:**")
        st.markdown("1. **Mean Throughput** - Primary load indicator")
        st.markdown("2. **Max Throughput** - Peak traffic detection")
        st.markdown("3. **Std Throughput** - Traffic variability")
        st.markdown("")
        st.markdown("**Model Behavior:**")
        st.markdown("- High throughput ‚Üí Higher congestion probability")
        st.markdown("- High variability ‚Üí Traffic instability signal")
        st.markdown("- Rising trend ‚Üí Early warning indicator")
    
    st.markdown("---")
    
    # Timeline Visualization
    st.subheader("üìà Traffic Pattern Timeline")
    
    window_start = int(row['window_start_slot'])
    context_window = 200
    
    context_data = link_data[
        (link_data['window_start_slot'] >= window_start - context_window) &
        (link_data['window_start_slot'] <= window_start + context_window)
    ].sort_values('window_start_slot')
    
    if len(context_data) > 0:
        fig = make_subplots(
            rows=2, cols=1,
            subplot_titles=('Throughput Over Time', 'Congestion Predictions'),
            row_heights=[0.6, 0.4],
            vertical_spacing=0.15
        )
        
        fig.add_trace(
            go.Scatter(
                x=context_data['window_start_slot'],
                y=context_data['mean_throughput'],
                mode='lines',
                name='Mean Throughput',
                line=dict(color='#3b82f6', width=2)
            ),
            row=1, col=1
        )
        
        fig.add_vline(
            x=window_start,
            line_dash="dash",
            line_color="orange",
            annotation_text="Current Window",
            row=1, col=1
        )
        
        colors = ['#10b981' if c == 0 else '#ef4444' for c in context_data['future_congestion']]
        
        fig.add_trace(
            go.Scatter(
                x=context_data['window_start_slot'],
                y=context_data['future_congestion'],
                mode='markers',
                name='Future Congestion State',
                marker=dict(size=8, color=colors)
            ),
            row=2, col=1
        )
        
        fig.add_trace(
            go.Scatter(
                x=[window_start],
                y=[prediction],
                mode='markers',
                name='Current Prediction',
                marker=dict(size=20, color='orange', symbol='star')
            ),
            row=2, col=1
        )
        
        fig.update_xaxes(title_text="Slot Number", row=2, col=1)
        fig.update_yaxes(title_text="Throughput (Mbps)", row=1, col=1)
        fig.update_yaxes(title_text="State (0=Normal, 1=Congested)", row=2, col=1)
        
        fig.update_layout(height=600, showlegend=True)
        
        st.plotly_chart(fig, use_container_width=True)

st.markdown("---")

# Explanation Section
st.subheader("üìö How Predictions Work")

col1, col2 = st.columns(2)

with col1:
    st.markdown("**üîÆ Prediction Process (Refactored Model)**")
    st.markdown("**1. Window Analysis**")
    st.markdown("Extract 12 safe features from 50-slot window:")
    st.markdown("- Throughput statistics (mean, max, std, trend)")
    st.markdown("- Loss patterns (count, burst, time since last)")
    st.markdown("- Derived features (acceleration, burstiness)")
    st.markdown("- Link identification (Link_1, Link_2, Link_3)")
    st.markdown("")
    st.markdown("‚ö†Ô∏è **Removed leaking features:** avg_utilization, loss_rate, peak_utilization")
    st.markdown("")
    st.markdown("**2. Feature Scaling**")
    st.markdown("Normalize all features to 0-1 range for consistent model input.")
    st.markdown("")
    st.markdown("**3. Gradient Boosting Model**")
    st.markdown("Ensemble of 100 decision trees predicts future state with confidence score.")
    st.markdown("")
    st.markdown("**4. Early Warning**")
    st.markdown("50-slot advance prediction allows time for proactive intervention.")

with col2:
    st.markdown("**üíº Business Value**")
    st.markdown("**üéØ Proactive Management**")
    st.markdown("Predict congestion BEFORE it impacts users - time for intervention.")
    st.markdown("")
    st.markdown("**‚ö° Real-Time Speed**")
    st.markdown("Inference <1ms - monitor all links simultaneously.")
    st.markdown("")
    st.markdown("**üìä High Accuracy (Refactored Model)**")
    st.markdown("- **92.88%** Overall Accuracy")
    st.markdown("- **96.42%** Prevention Rate (detects 96% of events 50 slots ahead)")
    st.markdown("- **3.58%** Miss Rate (only 2,188 missed out of 61,037)")
    st.markdown("- **Realistic probabilities:** 2.6%-98.9% (no fake 100%)")
    st.markdown("")
    st.markdown("**üí∞ Cost Savings**")
    st.markdown("- Prevent SLA violations")
    st.markdown("- Reduce emergency responses")
    st.markdown("- Optimize capacity planning")
    st.markdown("- Improve user satisfaction")

st.markdown("---")
st.info("üîÆ Refactored Model (No Leakage) | ‚ö° Sub-millisecond inference | üéØ 92.88% accuracy | üìä 96.42% prevention rate | 2.6%-98.9% realistic probabilities")
st.caption("Click 'Get Random Window' to test the model on different traffic patterns!")
